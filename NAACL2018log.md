NAACL2018読み会のログ
#### 論文リスト:
- Self-Attentive Residual Decoder for Neural Machine Translation /
  [issue](https://github.com/OnizukaLab/ConferenceProceedings/issues/2) /
  [slide](https://www.slideshare.net/OnizukaLab/nomoto-n18-1124)
- Delete, Retrieve, Generate: A Simple Approach to Sentiment and Style Transfer /
  [issue](https://github.com/OnizukaLab/ConferenceProceedings/issues/13)
- Querying Word Embeddings for Similarity and Relatedness /
  [issue](https://github.com/OnizukaLab/ConferenceProceedings/issues/1)
- A Deep Ensemble Model with Slot Alignment for Sequence-to-Sequence Natural Language Generation /
  [issue](https://github.com/OnizukaLab/ConferenceProceedings/issues/3)
- Neural Text Generation in Stories Using Entity Representations as Context /
  [issue](https://github.com/OnizukaLab/ConferenceProceedings/issues/4)
- Learning to Map Context- Dependent Sentences to Executable Formal Queries /
  [issue](https://github.com/OnizukaLab/ConferenceProceedings/issues/5)
- Recurrent Neural Networks as Weighted Language Recognizers /
  [issue](https://github.com/OnizukaLab/ConferenceProceedings/issues/6)
- Classical Structured Prediction Losses for Sequence to Sequence Learning /
  [issue](https://github.com/OnizukaLab/ConferenceProceedings/issues/7)
- Deep contextualized word representation /
  [issue](https://github.com/OnizukaLab/ConferenceProceedings/issues/8)
- Query and Output: Generating Words by Querying Distributed Word Representations for Paraphrase Generation /
  [issue](https://github.com/OnizukaLab/ConferenceProceedings/issues/9)
- Universal Neural Machine Translation for Extremely Low Resource Languages /
  [issue](https://github.com/OnizukaLab/ConferenceProceedings/issues/10)
- QuickEdit: Editing Text & Translations by Crossing Words Out /
  [issue](https://github.com/OnizukaLab/ConferenceProceedings/issues/11)
- Combining Character and Word Information in Neural Machine Translation Using a Multi-Level Attention /
  [issue](https://github.com/OnizukaLab/ConferenceProceedings/issues/12)
